import torch
import numpy as np
import json
import base64
import io
import os
import time
import cv2
from PIL import Image
import folder_paths
from server import PromptServer
from aiohttp import web

# å…¨å±€å†…å­˜ç¼“å­˜ï¼š{ image_path: numpy_array_bgr }
SK_V3_IMAGE_CACHE = {}

class InteractiveAnnotationToolV3:
    @classmethod
    def INPUT_TYPES(s):
        input_dir = folder_paths.get_input_directory()
        files = []
        if os.path.exists(input_dir):
            for root, dirs, filenames in os.walk(input_dir):
                for f in filenames:
                    if os.path.isfile(os.path.join(root, f)):
                        rel_path = os.path.relpath(os.path.join(root, f), input_dir)
                        rel_path = rel_path.replace("\\", "/")
                        files.append(rel_path)
        
        return {
            "required": {
                "image": (sorted(files), {"image_upload": True}),
                "points_data": ("STRING", {"default": "[]"}),
                "mask_data": ("STRING", {"default": ""}),
            },
        }

    RETURN_TYPES = ("IMAGE", "MASK", "IMAGE", "IMAGE", "STRING")
    RETURN_NAMES = ("images", "mask", "image_doodle", "image_points", "json_points")
    FUNCTION = "process"
    CATEGORY = "ğŸŒŸSKèŠ‚ç‚¹åº“/å·¥å…·"

    def process(self, image, points_data, mask_data):
        if not image:
            empty_img = torch.zeros((1, 512, 512, 3))
            empty_mask = torch.zeros((1, 512, 512))
            return (empty_img, empty_mask, empty_img, empty_img, "[]")

        image_path = folder_paths.get_annotated_filepath(image)
        
        # 1. ä¼˜å…ˆä»ç¼“å­˜è¯»å– OpenCV æ ¼å¼ (BGR)
        if image_path in SK_V3_IMAGE_CACHE:
            base_bgr = SK_V3_IMAGE_CACHE[image_path]
        else:
            # OpenCV è¯»å–é€Ÿåº¦å¿«äº PIL
            try:
                base_bgr = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)
                if base_bgr is None: raise Exception("OpenCV read failed")
                SK_V3_IMAGE_CACHE[image_path] = base_bgr
            except:
                # é™çº§åˆ° PIL è¯»å–
                pil_img = Image.open(image_path).convert("RGB")
                base_bgr = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
                SK_V3_IMAGE_CACHE[image_path] = base_bgr

        h, w = base_bgr.shape[:2]
        base_rgb = cv2.cvtColor(base_bgr, cv2.COLOR_BGR2RGB)

        # 2. å‡†å¤‡æ¶‚é¸¦å±‚ (OpenCV RGBA)
        doodle_rgba = np.zeros((h, w, 4), dtype=np.uint8)
        
        if mask_data and "," in mask_data:
            try:
                encoded = mask_data.split(",")[1]
                m_bytes = base64.b64decode(encoded)
                # ä½¿ç”¨ OpenCV è§£ç  PNG æ•°æ®
                m_arr = cv2.imdecode(np.frombuffer(m_bytes, np.uint8), cv2.IMREAD_UNCHANGED)
                
                if m_arr is not None:
                    if m_arr.shape[:2] != (h, w):
                        m_arr = cv2.resize(m_arr, (w, h), interpolation=cv2.INTER_LINEAR)
                    
                    # ç¡®ä¿æ˜¯ 4 é€šé“
                    if len(m_arr.shape) == 2: # ç°åº¦è½¬ RGBA
                        m_arr = cv2.cvtColor(m_arr, cv2.COLOR_GRAY2RGBA)
                    elif m_arr.shape[2] == 3: # RGB è½¬ RGBA
                        m_arr = cv2.cvtColor(m_arr, cv2.COLOR_RGB2RGBA)
                    
                    doodle_rgba = m_arr
            except Exception as e:
                print(f"SK-Nodes-V3 Error: Mask decode failure: {e}")

        # 3. OpenCV é«˜é€Ÿç»˜åˆ¶å‡½æ•°
        def draw_points_cv2(img_rgb, pts_list):
            if not pts_list: return img_rgb
            
            # è½¬æ¢ä¸º BGR è¿›è¡Œç»˜åˆ¶ï¼Œæœ€åè½¬å› RGB
            canvas = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
            
            r = max(int(min(w, h) * 0.015), 10)
            font_scale = r * 0.04
            thickness = max(int(r * 0.15), 1)
            
            for i, pt in enumerate(pts_list):
                try:
                    px, py = int(float(pt['x'])), int(float(pt['y']))
                    # ç»˜åˆ¶åº•åœ† (BGR: è“è‰²é€šé“åœ¨æœ€åï¼Œçº¢è‰²åœ¨å‰ -> è¿™é‡Œæˆ‘ä»¬è¦çº¢è‰²)
                    # å®é™…ä¸Š OpenCV é»˜è®¤ BGRï¼Œæ‰€ä»¥çº¢è‰²æ˜¯ (0, 0, 255)
                    cv2.circle(canvas, (px, py), r, (0, 0, 255), -1) 
                    cv2.circle(canvas, (px, py), r, (255, 255, 255), thickness)
                    
                    text = str(i+1)
                    (fw, fh), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)
                    tx = int(px - fw / 2)
                    ty = int(py + fh / 2)
                    cv2.putText(canvas, text, (tx, ty), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)
                except: pass
            
            return cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)

        try:
            pts = json.loads(points_data)
        except:
            pts = []

        # --- åˆæˆè¾“å‡º 1: images (åŸå›¾ + æ¶‚é¸¦ + æ ‡æ³¨ç‚¹) ---
        # ä¼˜åŒ– Alpha Blend æ€§èƒ½
        def overlay_rgba(bg_rgb, fg_rgba):
            # åˆ†ç¦»é€šé“å¹¶å½’ä¸€åŒ– alpha
            alpha = (fg_rgba[:, :, 3] / 255.0)[:, :, np.newaxis]
            # çŸ¢é‡åŒ–åˆæˆï¼š(fg * alpha) + (bg * (1 - alpha))
            result = (fg_rgba[:, :, :3] * alpha + bg_rgb * (1 - alpha)).astype(np.uint8)
            return result

        img_doodle_rgb = overlay_rgba(base_rgb, doodle_rgba)
        img_all_rgb = draw_points_cv2(img_doodle_rgb, pts)

        # --- è¾“å‡º 2: mask ---
        mask_arr = doodle_rgba[:, :, 3].astype(np.float32) / 255.0
        mask_tensor = torch.from_numpy(mask_arr)[None,]

        # --- åˆæˆè¾“å‡º 4: image_points (ä»…åŸå›¾ + ç‚¹) ---
        img_points_rgb = draw_points_cv2(base_rgb, pts)

        # --- è½¬æ¢ä¸º Tensor ---
        def np_to_tensor(np_img):
            return torch.from_numpy(np_img.astype(np.float32) / 255.0)[None,]

        return (
            np_to_tensor(img_all_rgb),
            mask_tensor,
            np_to_tensor(img_doodle_rgb),
            np_to_tensor(img_points_rgb),
            json.dumps(pts)
        )

    @classmethod
    def IS_CHANGED(s, image, points_data, mask_data):
        import hashlib
        m = hashlib.sha256()
        m.update(image.encode())
        m.update(points_data.encode())
        m.update(mask_data.encode())
        return m.hexdigest()

# API è·¯ç”±æ³¨å†Œ
@PromptServer.instance.routes.post("/api/sk-marks/save_v3")
async def save_v3_marks(request):
    try:
        data = await request.json()
        image_name = data.get("image")
        points = data.get("points", [])
        mask_data = data.get("mask_data", "")
        
        image_path = folder_paths.get_annotated_filepath(image_name)
        if not os.path.exists(image_path):
            return web.Response(status=404, text="Image not found")
        
        # 1. ä¼˜å…ˆä½¿ç”¨ç¼“å­˜ (BGR æ ¼å¼)
        if image_path in SK_V3_IMAGE_CACHE:
            base_bgr = SK_V3_IMAGE_CACHE[image_path]
        else:
            base_bgr = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)
            SK_V3_IMAGE_CACHE[image_path] = base_bgr
            
        h, w = base_bgr.shape[:2]
        
        # 2. æ¶‚é¸¦åˆæˆ (Alpha Blend) - ä¿æŒåœ¨ BGR ç©ºé—´å¤„ç†ä»¥åŠ å¿«é€Ÿåº¦
        final_bgr = base_bgr.copy()
        
        if mask_data and "," in mask_data:
            encoded = mask_data.split(",")[1]
            m_bytes = base64.b64decode(encoded)
            m_arr = cv2.imdecode(np.frombuffer(m_bytes, np.uint8), cv2.IMREAD_UNCHANGED)
            
            if m_arr is not None:
                if m_arr.shape[:2] != (h, w):
                    m_arr = cv2.resize(m_arr, (w, h))
                
                # çŸ¢é‡åŒ– Alpha æ··åˆ (BGR ç©ºé—´)
                alpha = (m_arr[:, :, 3] / 255.0)[:, :, np.newaxis]
                final_bgr = (m_arr[:, :, :3] * alpha + final_bgr * (1.0 - alpha)).astype(np.uint8)

        # 3. ç»˜åˆ¶ç‚¹ä½ (OpenCV çŸ¢é‡åŒ–ç»˜åˆ¶)
        r = max(int(min(w, h) * 0.015), 10)
        font_scale = r * 0.04
        thickness = 2
        
        for i, pt in enumerate(points):
            try:
                px, py = int(float(pt['x'])), int(float(pt['y']))
                # BGR é¢œè‰²: çº¢ (0,0,255), ç™½ (255,255,255)
                cv2.circle(final_bgr, (px, py), r, (0, 0, 255), -1)
                cv2.circle(final_bgr, (px, py), r, (255, 255, 255), thickness)
                
                text = str(i+1)
                (fw, fh), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)
                tx = int(px - fw / 2)
                ty = int(py + fh / 2)
                cv2.putText(final_bgr, text, (tx, ty), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)
            except: pass

        # 4. ä¿å­˜ä¸º JPG (å‹ç¼©è´¨é‡ 85)
        output_dir = folder_paths.get_temp_directory()
        # ä½¿ç”¨ JPG åç¼€
        filename = f"sk_v3_preview_{int(time.time())}.jpg"
        save_path = os.path.join(output_dir, filename)
        
        # cv2.imwrite é€Ÿåº¦æå¿«ï¼Œä¸”æ”¯æŒå‹ç¼©å‚æ•°
        cv2.imwrite(save_path, final_bgr, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
        
        return web.json_response({
            "status": "success",
            "preview_name": filename
        })
    except Exception as e:
        print(f"SK-Nodes-V3 API Error: {e}")
        return web.json_response({"status": "error", "message": str(e)}, status=500)

NODE_CLASS_MAPPINGS = {"InteractiveAnnotationToolV3": InteractiveAnnotationToolV3}
NODE_DISPLAY_NAME_MAPPINGS = {"InteractiveAnnotationToolV3": "ğŸ–Œï¸äº¤äº’å¼åºå·æ ‡æ³¨å·¥å…·V3-alpha"}
